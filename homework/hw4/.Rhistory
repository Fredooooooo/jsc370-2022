hitter_tree  <-rpart(Salary~., data=hitter, method="anova", control = list(cp=optimalcp))
plotcp(hitter_tree)
hitter_tree$cptable
min(hitter_tree$cptable[,'xerror']) * nrow(hitter)
View(hitter)
View(hitter)
hitter_bag <- randomForest(Salary~., data=train, mtry=19, na.action = na.omit)
print("OOB error: ", sum(hitter_bag$err.rate[,1]))
varImpPlot(heart_bag, n.var = 13, col="red")
hitter_bag <- randomForest(Salary~., data=train, mtry=19, na.action = na.omit)
print("OOB error: d%", sum(hitter_bag$err.rate[,1]))
varImpPlot(heart_bag, n.var = 13, col="red")
hitter_bag <- randomForest(Salary~., data=train, mtry=19, na.action = na.omit)
print("OOB error: %d", sum(hitter_bag$err.rate[,1]))
varImpPlot(hitter_bag, n.var = 13, col="red")
sum(importance(hitter_bag))
hitter_bag <- randomForest(Salary~., data=train, mtry=19, na.action = na.omit)
sprintf("OOB error: %d", sum(hitter_bag$err.rate[,1]))
varImpPlot(hitter_bag, n.var = 13, col="red")
sum(importance(hitter_bag))
hitter_tree$cptable
sprintf("OOB error: %d", min(hitter_tree$cptable[,'xerror']) * nrow(hitter))
hitter_tree$cptable
sprintf("OOB error: %f", min(hitter_tree$cptable[,'xerror']) * nrow(hitter))
hitter_bag <- randomForest(Salary~., data=train, mtry=19, na.action = na.omit)
sprintf("OOB error: %f", sum(hitter_bag$err.rate[,1]))
varImpPlot(hitter_bag, n.var = 13, col="red")
sum(importance(hitter_bag))
hitter_bag <- randomForest(Salary~., data=train, mtry=19, na.action = na.omit)
hitter_bag$err.rate
sprintf("OOB error: %f", sum(hitter_bag$err.rate[,1]))
varImpPlot(hitter_bag, n.var = 13, col="red")
sum(importance(hitter_bag))
hitter_bag <- randomForest(Salary~., data=train, mtry=19, na.action = na.omit)
hitter_bag$err.rate[,1]
sprintf("OOB error: %f", sum(hitter_bag$err.rate[,1]))
varImpPlot(hitter_bag, n.var = 13, col="red")
sum(importance(hitter_bag))
library(parallel)
library(foreach)
library(doParallel)
# Total row sums
fun1 <- function(mat) {
n <- nrow(mat)
ans <- double(n)
for (i in 1:n) {
ans[i] <- sum(mat[i, ])
}
ans
}
fun1alt <- function(mat) {
# YOUR CODE HERE
rowSums(mat)
}
# Cumulative sum by row
fun2 <- function(mat) {
n <- nrow(mat)
k <- ncol(mat)
ans <- mat
for (i in 1:n) {
for (j in 2:k) {
ans[i,j] <- mat[i, j] + ans[i, j - 1]
}
}
ans
}
fun2alt <- function(mat) {
# YOUR CODE HERE
n <- nrow(mat)
ans <- mat
for(i in 1:n) {
ans[i,] <- cumsum(ans[i,])
}
ans
}
# Use the data with this code
set.seed(2315)
dat <- matrix(rnorm(200 * 100), nrow = 200)
# Test for the first
microbenchmark::microbenchmark(
fun1(dat),
fun1alt(dat), check = "equivalent")
options(microbenchmark.unit="relative")
# Test for the second
microbenchmark::microbenchmark(
fun2(dat),
fun2alt(dat), check = "equivalent")
options(microbenchmark.unit="relative")
sim_pi <- function(n = 1000, i = NULL) {
p <- matrix(runif(n*2), ncol = 2)
mean(rowSums(p^2) < 1) * 4
}
# Here is an example of the run
set.seed(156)
sim_pi(1000) # 3.132
# This runs the simulation a 4,000 times, each with 10,000 points
set.seed(1231)
system.time({
ans <- unlist(lapply(1:4000, sim_pi, n = 10000))
print(mean(ans))
})
# YOUR CODE HERE
system.time({
# YOUR CODE HERE
cl <- makePSOCKcluster(4)
clusterExport(cl, varlist=NULL, envir = environment())
clusterSetRNGStream(cl, 370)
ans <- unlist(parLapply(cl, 1:4000, sim_pi, n = 10000))
print(mean(ans))
stopCluster(cl)
})
library(tidyverse)
library(rpart)
library(rpart.plot)
library(randomForest)
library(gbm)
library(xgboost)
hitter<-read.csv("hitters.csv")
hitter <- hitter %>% filter(!is.na(Salary))
head(hitter)
set.seed(67)
train_idx <- sample(nrow(hitter), round(0.7 * nrow(hitter)))
train <- hitter[train_idx,]
test <- hitter[-train_idx,]
hitter_tree <- rpart(Salary~., data=train, method = "anova", control = list(minsplit=10, minbucket=3, cp=0, xval=10))
rpart.plot(hitter_tree)
plotcp(hitter_tree)
printcp(hitter_tree)
optimalcp = hitter_tree$cptable[which.min(hitter_tree$cptable[,"xerror"]), "CP"]
optimalcp
hitter_tree_prune <- prune(hitter_tree, cp=optimalcp)
rpart.plot(hitter_tree_prune)
tree_pred <- predict(hitter_tree_prune, test)
test_tree <- cbind(test, tree_pred)
tree_mse <- sum((test_tree$tree_pred - test_tree$Salary)^2) / dim(test_tree)[1]
tree_mse
hitter_tree  <-rpart(Salary~., data=hitter, method="anova", control = list(cp=optimalcp))
plotcp(hitter_tree)
hitter_tree$cptable
sprintf("OOB error: %f", min(hitter_tree$cptable[,'xerror']) * nrow(hitter))
hitter_bag <- randomForest(Salary~., data=train, mtry=19, na.action = na.omit)
sprintf("OOB error: %f", sum(hitter_bag$err.rate[,1]))
varImpPlot(hitter_bag, n.var = 13, col="red")
sum(importance(hitter_bag))
hitter_bag <- randomForest(as.factor(Salary)~., data=train, mtry=19, na.action = na.omit)
sprintf("OOB error: %f", sum(hitter_bag$err.rate[,1]))
varImpPlot(hitter_bag, n.var = 13, col="red")
sum(importance(hitter_bag))
View(hitter)
View(hitter)
View(hitter)
View(hitter)
knitr::opts_chunk$set(eval = T, include  = T)
library(tidyverse)
library(rpart)
library(rpart.plot)
library(randomForest)
library(gbm)
library(xgboost)
heart<-read.csv("https://raw.githubusercontent.com/JSC370/jsc370-2022/main/data/heart/heart.csv")
head(heart)
set.seed(1984)
n <-1000
x <- runif(n,-5,5)
error <- rnorm(n, sd=0.5)
y <- sin(x) + error
nonlin <- data.frame(y=y,x=x)
train_size <-sample(1:1000, size=500)
nonlin_train <- nonlin[train_size,]
nonlin_test <- nonlin[-train_size,]
ggplot(nonlin_test, aes(y=y,x=x)) + geom_point()
treefit <- rpart(y~x, method="anova", control=list(cp=0), data = nonlin_train)
rpart.plot(treefit)
plotcp(treefit)
printcp(treefit)
optimalcp <- 0.0022
treepruned <- prune(treefit, cp = optimalcp)
summary(treepruned)
rpart.plot(treepruned)
View(train)
View(train)
train$Salary
hitter_bag <- randomForest(Salary~., data=train, na.action = na.omit)
sprintf("OOB error: %f", sum(hitter_bag$err.rate[,1]))
varImpPlot(hitter_bag, n.var = 13, col="red")
sum(importance(hitter_bag))
hitter_bag <- randomForest(as.numeric(Salary)~., data=train, mtry=19, na.action = na.omit)
sprintf("OOB error: %f", sum(hitter_bag$err.rate[,1]))
varImpPlot(hitter_bag, n.var = 13, col="red")
sum(importance(hitter_bag))
hitter_bag <- randomForest(as.numeric(Salary)~., data=train, mtry=19, na.action = na.omit)
hitter_bag
sprintf("OOB error: %f", sum(hitter_bag$err.rate[,1]))
varImpPlot(hitter_bag, n.var = 13, col="red")
sum(importance(hitter_bag))
heart_bag <- randomForest(as.factor(AHD)~., data=train, mtry=13, na.action = na.omit)
set.seed(1234)
train_idx <- sample(nrow(heart), round(0.7 * nrow(heart)))
train <- heart[train_idx,]
test <- heart[-train_idx,]
heart_tree <- rpart(AHD~., data=train, method = "class", control = list(minsplit=10, minbucket=3, cp=0, xval=10))
rpart.plot(heart_tree)
plotcp(heart_tree)
printcp(heart_tree)
optimalcp = heart_tree$cptable[which.min(heart_tree$cptable[,"xerror"]), "CP"]
optimalcp
heart_tree_prune <- prune(heart_tree, cp=optimalcp)
rpart.plot(heart_tree_prune)
heart_pred <- predict(heart_tree_prune, test)
heart_pred <- as.data.frame(heart_pred)
heart_pred$AHD <- ifelse(heart_pred$Yes>0.5, "yes", "no")
confmatrix_table <- table(true=test$AHD, predicted=heart_pred$AHD)
misclass_err <- (confmatrix_table[1,2] + confmatrix_table[2,1]) / nrow(test)
misclass_err
heart_tree  <-rpart(AHD~., data=heart, method="class", control = list(cp=optimalcp))
plotcp(heart_tree)
heart_tree$cptable
min(heart_tree$cptable[,'xerror']) * nrow(heart)
heart_bag <- randomForest(as.factor(AHD)~., data=train, mtry=13, na.action = na.omit)
sum(heart_bag$err.rate[,1])
varImpPlot(heart_bag, n.var = 13, col="red")
sum(importance(heart_bag))
hitter_bag <- randomForest(as.numeric(Salary)~., data=train, mtry=19, na.action = na.omit)
library(parallel)
library(foreach)
library(doParallel)
# Total row sums
fun1 <- function(mat) {
n <- nrow(mat)
ans <- double(n)
for (i in 1:n) {
ans[i] <- sum(mat[i, ])
}
ans
}
fun1alt <- function(mat) {
# YOUR CODE HERE
rowSums(mat)
}
# Cumulative sum by row
fun2 <- function(mat) {
n <- nrow(mat)
k <- ncol(mat)
ans <- mat
for (i in 1:n) {
for (j in 2:k) {
ans[i,j] <- mat[i, j] + ans[i, j - 1]
}
}
ans
}
fun2alt <- function(mat) {
# YOUR CODE HERE
n <- nrow(mat)
ans <- mat
for(i in 1:n) {
ans[i,] <- cumsum(ans[i,])
}
ans
}
# Use the data with this code
set.seed(2315)
dat <- matrix(rnorm(200 * 100), nrow = 200)
# Test for the first
microbenchmark::microbenchmark(
fun1(dat),
fun1alt(dat), check = "equivalent")
options(microbenchmark.unit="relative")
# Test for the second
microbenchmark::microbenchmark(
fun2(dat),
fun2alt(dat), check = "equivalent")
options(microbenchmark.unit="relative")
sim_pi <- function(n = 1000, i = NULL) {
p <- matrix(runif(n*2), ncol = 2)
mean(rowSums(p^2) < 1) * 4
}
# Here is an example of the run
set.seed(156)
sim_pi(1000) # 3.132
# This runs the simulation a 4,000 times, each with 10,000 points
set.seed(1231)
system.time({
ans <- unlist(lapply(1:4000, sim_pi, n = 10000))
print(mean(ans))
})
# YOUR CODE HERE
system.time({
# YOUR CODE HERE
cl <- makePSOCKcluster(4)
clusterExport(cl, varlist=NULL, envir = environment())
clusterSetRNGStream(cl, 370)
ans <- unlist(parLapply(cl, 1:4000, sim_pi, n = 10000))
print(mean(ans))
stopCluster(cl)
})
library(tidyverse)
library(rpart)
library(rpart.plot)
library(randomForest)
library(gbm)
library(xgboost)
hitter<-read.csv("hitters.csv")
hitter <- hitter %>% filter(!is.na(Salary))
head(hitter)
set.seed(67)
train_idx <- sample(nrow(hitter), round(0.7 * nrow(hitter)))
train <- hitter[train_idx,]
test <- hitter[-train_idx,]
hitter_tree <- rpart(Salary~., data=train, method = "anova",
control = list(minsplit=10, minbucket=3, cp=0, xval=10))
rpart.plot(hitter_tree)
plotcp(hitter_tree)
printcp(hitter_tree)
optimalcp = hitter_tree$cptable[which.min(hitter_tree$cptable[,"xerror"]), "CP"]
optimalcp
hitter_tree_prune <- prune(hitter_tree, cp=optimalcp)
rpart.plot(hitter_tree_prune)
tree_pred <- predict(hitter_tree_prune, test)
test_tree <- cbind(test, tree_pred)
tree_mse <- sum((test_tree$tree_pred - test_tree$Salary)^2) / dim(test_tree)[1]
tree_mse
hitter_tree  <-rpart(Salary~., data=hitter, method="anova",
control = list(cp=optimalcp))
plotcp(hitter_tree)
hitter_tree$cptable
sprintf("OOB error: %f", min(hitter_tree$cptable[,'xerror']) * nrow(hitter))
hitter_bag <- randomForest(Salary~., data=train, mtry=19, na.action = na.omit)
hitter_bag$mse
sprintf("OOB error: %f", sum(hitter_bag$err.rate[,1]))
varImpPlot(hitter_bag, n.var = 13, col="red")
sum(importance(hitter_bag))
hitter_bag <- randomForest(Salary~., data=train, mtry=19, na.action = na.omit)
hitter_bag$mse[,1]
hitter_bag <- randomForest(Salary~., data=train, mtry=19, na.action = na.omit)
hitter_bag$rsq
sprintf("OOB error: %f", sum(hitter_bag$err.rate[,1]))
varImpPlot(hitter_bag, n.var = 13, col="red")
sum(importance(hitter_bag))
hitter_bag <- randomForest(Salary~., data=train, mtry=19, na.action = na.omit)
hitter_bag
sprintf("OOB error: %f", sum(hitter_bag$err.rate[,1]))
varImpPlot(hitter_bag, n.var = 13, col="red")
sum(importance(hitter_bag))
hitter_bag <- randomForest(Salary~., data=train, mtry=19, na.action = na.omit)
hitter_bag
varImpPlot(hitter_bag, n.var = 19, col="red")
sum(importance(hitter_bag))
set.seed(67)
hitter_bag <- randomForest(Salary~., data=train, mtry=19, na.action = na.omit)
hitter_bag
varImpPlot(hitter_bag, n.var = 19, col="red")
sum(importance(hitter_bag))
set.seed(67)
hitter_bag <- randomForest(Salary~., data=train, mtry=19, na.action = na.omit)
hitter_bag
varImpPlot(hitter_bag, n.var = 19, col="red")
sum(importance(hitter_bag))
set.seed(67)
hitter_bag <- randomForest(Salary~., data=train, mtry=19, na.action = na.omit)
hitter_bag
varImpPlot(hitter_bag, n.var = 19, col="red")
sprintf("Sum of variable importance: %d", sum(importance(hitter_bag)))
set.seed(67)
hitter_bag <- randomForest(Salary~., data=train, mtry=19, na.action = na.omit)
hitter_bag
varImpPlot(hitter_bag, n.var = 19, col="red")
sprintf("Sum of variable importance: %f", sum(importance(hitter_bag)))
set.seed(67)
hitter_bag <- randomForest(Salary~., data=train, na.action = na.omit)
hitter_bag
varImpPlot(hitter_bag, n.var = 19, col="blue")
sprintf("Sum of variable importance: %f", sum(importance(hitter_bag)))
set.seed(67)
hitter_bag <- randomForest(Salary~., data=train, mtry=19, na.action = na.omit)
hitter_bag
varImpPlot(hitter_bag, n.var = 19, col="red")
sprintf("Sum of variable importance: %f", sum(importance(hitter_bag)))
tree_pred <- predict(hitter_bag, test)
test_tree <- cbind(test, tree_pred)
tree_mse <- sum((test_tree$tree_pred - test_tree$Salary)^2) / dim(test_tree)[1]
tree_mse
set.seed(67)
hitter_bag <- randomForest(Salary~., data=hitter, mtry=19, na.action = na.omit)
hitter_bag
set.seed(67)
hitter_bag <- randomForest(Salary~., data=hitter, mtry=19, na.action = na.omit)
sqrt(hitter_bag$mse)
set.seed(67)
hitter_bag <- randomForest(Salary~., data=hitter, mtry=19, na.action = na.omit)
sqrt(hitter_bag$mse[which.min(hitter_bag$mse)])
set.seed(67)
hitter_bag <- randomForest(Salary~., data=hitter, mtry=19, na.action = na.omit)
sqrt(hitter_bag$mse[which.min(hitter_bag$mse)])
sprintf("OOB error: %f", min(hitter_bag$rsq) * nrow(hitter))
set.seed(67)
hitter_bag <- randomForest(Salary~., data=hitter, mtry=19, na.action = na.omit)
sqrt(hitter_bag$mse[which.min(hitter_bag$mse)])
hitter_bag$oob.times
set.seed(67)
hitter_bag <- randomForest(Salary~., data=hitter, mtry=19, na.action = na.omit)
sqrt(hitter_bag$mse[which.min(hitter_bag$mse)])
sqrt(hitter_bag$mse)
set.seed(67)
hitter_bag <- randomForest(Salary~., data=train, mtry=19, na.action = na.omit)
hitter_bag
mean(hitter_bag$mse)
varImpPlot(hitter_bag, n.var = 19, col="red")
sprintf("Sum of variable importance: %f", sum(importance(hitter_bag)))
set.seed(67)
hitter_bag <- randomForest(Salary~., data=train, mtry=19, na.action = na.omit)
hitter_bag
varImpPlot(hitter_bag, n.var = 19, col="red")
sprintf("Sum of variable importance: %f", sum(importance(hitter_bag)))
set.seed(67)
hitter_bag <- randomForest(Salary~., data=hitter, mtry=19, na.action = na.omit)
hitter_bag
sqrt(hitter_bag$mse[which.min(hitter_bag$mse)])
set.seed(67)
hitter_bag <- randomForest(Salary~., data=train, mtry=19, na.action = na.omit)
hitter_bag
mean(hitter_bag$mse)
varImpPlot(hitter_bag, n.var = 19, col="red")
sprintf("Sum of variable importance: %f", sum(importance(hitter_bag)))
set.seed(67)
hitter_bag <- randomForest(Salary~., data=hitter, mtry=19, na.action = na.omit)
hitter_bag
mean(hitter_bag$mse)
sqrt(hitter_bag$mse[which.min(hitter_bag$mse)])
set.seed(67)
hitter_bag <- randomForest(Salary~., data=train, mtry=19, na.action = na.omit)
hitter_bag
# mean(hitter_bag$mse)
varImpPlot(hitter_bag, n.var = 19, col="red")
sprintf("Sum of variable importance: %f", sum(importance(hitter_bag)))
set.seed(67)
hitter_bag <- randomForest(Salary~., data=hitter, mtry=19, na.action = na.omit)
hitter_bag
# mean(hitter_bag$mse)
sqrt(hitter_bag$mse[which.min(hitter_bag$mse)])
set.seed(67)
hitter_bag <- randomForest(Salary~., data=train, mtry=19, na.action = na.omit)
hitter_bag
mean(hitter_bag$mse)
varImpPlot(hitter_bag, n.var = 19, col="red")
sprintf("Sum of variable importance: %f", sum(importance(hitter_bag)))
set.seed(67)
hitter_bag <- randomForest(Salary~., data=hitter, mtry=19, na.action = na.omit)
hitter_bag
mean(hitter_bag$mse)
sqrt(hitter_bag$mse[which.min(hitter_bag$mse)])
tree_pred <- predict(hitter_rf, test)
library(tidyverse)
library(rpart)
library(rpart.plot)
library(randomForest)
library(gbm)
library(xgboost)
hitter<-read.csv("hitters.csv")
hitter <- hitter %>% filter(!is.na(Salary))
head(hitter)
set.seed(67)
train_idx <- sample(nrow(hitter), round(0.7 * nrow(hitter)))
train <- hitter[train_idx,]
test <- hitter[-train_idx,]
hitter_tree <- rpart(Salary~., data=train, method = "anova",
control = list(minsplit=10, minbucket=3, cp=0, xval=10))
rpart.plot(hitter_tree)
plotcp(hitter_tree)
printcp(hitter_tree)
optimalcp = hitter_tree$cptable[which.min(hitter_tree$cptable[,"xerror"]), "CP"]
optimalcp
hitter_tree_prune <- prune(hitter_tree, cp=optimalcp)
rpart.plot(hitter_tree_prune)
tree_pred <- predict(hitter_tree_prune, test)
test_tree <- cbind(test, tree_pred)
tree_mse <- sum((test_tree$tree_pred - test_tree$Salary)^2) / dim(test_tree)[1]
tree_mse
hitter_tree  <-rpart(Salary~., data=hitter, method="anova",
control = list(cp=optimalcp))
plotcp(hitter_tree)
hitter_tree$cptable
sprintf("OOB error: %f", min(hitter_tree$cptable[,'xerror']) * nrow(hitter))
set.seed(67)
hitter_bag <- randomForest(Salary~., data=train, mtry=19, na.action = na.omit)
hitter_bag
# mean(hitter_bag$mse)
varImpPlot(hitter_bag, n.var = 19, col="red")
sprintf("Sum of variable importance: %f", sum(importance(hitter_bag)))
tree_pred <- predict(hitter_bag, test)
test_tree <- cbind(test, tree_pred)
tree_mse <- sum((test_tree$tree_pred - test_tree$Salary)^2) / dim(test_tree)[1]
tree_mse
set.seed(67)
hitter_bag <- randomForest(Salary~., data=hitter, mtry=19, na.action = na.omit)
hitter_bag
mean(hitter_bag$mse)
sqrt(hitter_bag$mse[which.min(hitter_bag$mse)])
set.seed(67)
hitter_rf <- randomForest(Salary~., data=train, na.action = na.omit)
hitter_rf
varImpPlot(hitter_rf, n.var = 19, col="blue")
sprintf("Sum of variable importance: %f", sum(importance(hitter_rf)))
tree_pred <- predict(hitter_rf, test)
test_tree <- cbind(test, tree_pred)
tree_mse <- sum((test_tree$tree_pred - test_tree$Salary)^2) / dim(test_tree)[1]
tree_mse
set.seed(67)
hitter_rf <- randomForest(Salary~., data=hitter, na.action = na.omit)
hitter_rf
mean(hitter_rf$mse)
sqrt(hitter_rf$mse[which.min(hitter_rf$mse)])
